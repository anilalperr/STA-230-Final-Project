---
title: "Final Project Testing"
author: "Ellis Chen"
date: "5/4/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(corrplot)
library(ggplot2)
library(caret)
library(tree)
library(datasets)
library(randomForest)
library(pROC)
```
Filtering and Cleaning
```{r}
project_data <- read.csv("C7 IYSdata.csv", header=TRUE, na.strings=c(".","NA", "-1"))
project_data = dplyr::select(project_data, gender, time.reading, time.HW, grade, time.no.adult, time.noschool.act, time.school.act, time.work, time.church)

project_data[project_data == "1-2 hours"] = "2 or less hours"
project_data[project_data == "0 hours"] = "2 or less hours"
project_data[project_data == "6-10 hours"] = "6 or more hours"
project_data[project_data == "11 or more hours"] = "6 or more hours"
```

Recoding for randomForest
```{r}
#Removing NA response values
project_data = subset(project_data, !is.na(time.HW))

project_data[is.na(project_data)] = "Not found"

numeric_data = subset(project_data, !is.na(time.HW))
numeric_data = transform(numeric_data, gender = factor(gender, 
       levels = c("Male", "Female"),
       labels = c(0, 1)))
numeric_data = transform(numeric_data, time.HW = factor(time.HW,
       levels = c("2 or less hours", "3-5 hours", "6 or more hours"),
       labels = c(2, 4, 6)))
# numeric_data = transform(numeric_data, time.HW = factor(time.HW, 
#        levels = c("2 or less hours", "3-5 hours", "6 or more hours", "Not found"),
#        labels = c(2, 4, 6, -1)))
numeric_data = transform(numeric_data, time.reading = factor(time.reading, 
       levels = c("2 or less hours", "3-5 hours", "6 or more hours", "Not found"),
       labels = c(2, 4, 6, -1)))
numeric_data = transform(numeric_data, time.noschool.act = factor(time.noschool.act, 
       levels = c("2 or less hours", "3-5 hours", "6 or more hours", "Not found"),
       labels = c(2, 4, 6, -1)))
numeric_data = transform(numeric_data, time.school.act = factor(time.school.act, 
       levels = c("2 or less hours", "3-5 hours", "6 or more hours", "Not found"),
       labels = c(2, 4, 6, -1)))
numeric_data = transform(numeric_data, grade = factor(grade, 
       levels = c("6th", "7th", "8th", "9th", "10th", "11th", "Not Found"),
       labels = c(6, 7, 8, 9, 10, 11, -1)))
numeric_data = transform(numeric_data, time.no.adult = factor(time.no.adult, 
       levels = c("2 or less hours", "3-5 hours", "6 or more hours", "Not found"),
       labels = c(2, 4, 6, -1)))
#numeric_data[is.na(numeric_data)] = -1
```

```{r}
set.seed(123)
knitr::opts_chunk$set(cache = T)

#Splitting our data into training and testing
set.seed(123)
trainIndex = createDataPartition(numeric_data$time.HW, p = 0.7, list = FALSE, times=1)

numericTrain = numeric_data[trainIndex,]

#Creating the random forests with varying mtry values (changes the number of variables at the split)
forest1 = randomForest(time.HW ~., data = numericTrain, importance = TRUE, ntree = 1000, mtry = 1, do.trace = TRUE, set.seed(123))

forest2 = randomForest(time.HW ~., data = numericTrain, importance = TRUE, ntree = 1000, mtry = 2, do.trace = TRUE, set.seed(123))
#mtry = 2 is best accuracy 

forest3 = randomForest(time.HW ~., data = numericTrain, importance = TRUE, ntree = 1000, mtry = 3, do.trace = TRUE, set.seed(123))

forest4 = randomForest(time.HW ~., data = numericTrain, importance = TRUE, ntree = 1000, mtry = 4, do.trace = TRUE, set.seed(123))

forest5 = randomForest(time.HW ~., data = numericTrain, importance = TRUE, ntree = 1000, mtry = 5, do.trace = TRUE, set.seed(123))

forest6 = randomForest(time.HW ~., data = numericTrain, importance = TRUE, ntree = 1000, mtry = 6, do.trace = TRUE, set.seed(123))

forest7 = randomForest(time.HW ~., data = numericTrain, importance = TRUE, ntree = 1000, mtry = 7, do.trace = TRUE, set.seed(123))

forest8 = randomForest(time.HW ~., data = numericTrain, importance = TRUE, ntree = 1000, mtry = 8, do.trace = TRUE, set.seed(123))

#Printing the models to assess accuracy and confusion matrix

forest1
forest2
forest3
forest4
forest5
forest6
forest7
forest8

#mtry = 2 is best accuracy 


#Printing variable importance plots for the most promising variables
varImpPlot(forest1, sort=TRUE)
varImpPlot(forest2, sort=TRUE)
varImpPlot(forest3, sort=TRUE)
varImpPlot(forest4, sort=TRUE)
#varImpPlot(forest10, sort=TRUE)

#Creating data frame based on the model accuracy
df <- data.frame(mtry  = c(1, 2, 3, 4, 5, 6, 7, 8),
                  OOBError = c(42.48, 42.4, 43.46, 44.56, 44.99, 45.3, 45.26, 46.16)
                  )
#Plotting the model accuracy
AccuracyPlot = ggplot(df, aes(x=mtry, y=OOBError, label=OOBError)) +
  geom_point(size=2, shape=1, stroke = 1) +
  geom_text(hjust=1.25, vjust=.5) +
  scale_x_continuous(breaks = seq(-1, 8, by = 1), name = "Number of Variables") +
  scale_y_continuous(name = "Out of Bag Error (%)") +
  coord_cartesian(xlim=c(0.5,10)) +
  ggtitle("Out of Bag Error and Number of Variables Sampled at Splits") 

AccuracyPlot
```
Evaluation Stuff
```{r}
# result.roc1 <- roc(numericTrain$time.HW, predictions1$`2 or less hours`)
# result.roc3 <- roc(projectTrain$time.HW, project.pred1$`3-5 hours`)
# result.roc4 <- roc(projectTrain$time.HW, project.pred1$`6 or more hours`)

# Put three ROC curves together
plot(result.roc2, print.thres="best", print.thres.best.method="closest.topleft", main = "two or less hours")
plot(result.roc3, print.thres="best", print.thres.best.method="closest.topleft", main = "3-5 hours prediction")
plot(result.roc4, print.thres="best", print.thres.best.method="closest.topleft", main = "six or more hours prediction")


auc2 = auc(projectTrain$time.HW, project.pred1$`2 or less hours`)
auc3 = auc(projectTrain$time.HW, project.pred1$`3-5 hours`)
auc4 = auc(projectTrain$time.HW, project.pred1$`6 or more hours`)
```

Other Tests
```{r}
trainIndex = createDataPartition(numeric_data$time.HW, p = 0.7, list = FALSE, times=1)
numericTrain = numeric_data[trainIndex,]
forest = randomForest(time.HW ~., data = numericTrain, importance = TRUE, ntree = 100, mtry = 2, do.trace = TRUE)
varImpPlot(forest, sort=TRUE)
```

```{r}
# Without NA values
project_data <- read.csv("C7 IYSdata.csv", header=TRUE, na.strings=c(".","NA"))
project_data = dplyr::select(project_data, gender, time.reading, time.HW, grade, time.no.adult, time.noschool.act, time.school.act, time.work, time.church)
project_data = na.omit(project_data)
project_data[project_data == "1-2 hours"] = "2 or less hours"
project_data[project_data == "0 hours"] = "2 or less hours"
project_data[project_data == "6-10 hours"] = "6 or more hours"
project_data[project_data == "11 or more hours"] = "6 or more hours"
```

```{r}
numeric_data = transform(project_data, gender = factor(gender, 
       levels = c("Male", "Female"),
       labels = c(0, 1)))
numeric_data = transform(numeric_data, time.HW = factor(time.HW, 
       levels = c("2 or less hours", "3-5 hours", "6 or more hours"),
       labels = c(2, 4, 6)))
numeric_data = transform(numeric_data, time.reading = factor(time.reading, 
       levels = c("2 or less hours", "3-5 hours", "6 or more hours"),
       labels = c(2, 4, 6)))
numeric_data = transform(numeric_data, time.noschool.act = factor(time.noschool.act, 
       levels = c("2 or less hours", "3-5 hours", "6 or more hours"),
       labels = c(2, 4, 6)))
numeric_data = transform(numeric_data, time.school.act = factor(time.school.act, 
       levels = c("2 or less hours", "3-5 hours", "6 or more hours"),
       labels = c(2, 4, 6)))
numeric_data = transform(numeric_data, grade = factor(grade, 
       levels = c("6th", "7th", "8th", "9th", "10th", "11th"),
       labels = c(6, 7, 8, 9, 10, 11)))
numeric_data = transform(numeric_data, time.no.adult = factor(time.no.adult, 
       levels = c("2 or less hours", "3-5 hours", "6 or more hours"),
       labels = c(2, 4, 6)))
numeric_data = na.omit(numeric_data)
```

```{r}
trainIndex = createDataPartition(numeric_data$time.HW, p = 0.7, list = FALSE, times=1)
numericTrain = numeric_data[trainIndex,]
forest = randomForest(time.HW ~., data = numericTrain, importance = TRUE, ntree = 1000, mtry = 2, do.trace = TRUE)
varImpPlot(forest, sort=TRUE)
```


```{R}
set.seed(123)
project_data = read.csv("C7 IYSdata.csv", header=TRUE, na.strings=c(".","NA"))
project_data[project_data == "1-2 hours"] = "2 or less hours"
project_data[project_data == "0 hours"] = "2 or less hours"
project_data[project_data == "6-10 hours"] = "6 or more hours"
project_data[project_data == "11 or more hours"] = "6 or more hours"
project_data[project_data == "Strongly agree"] = "Agree"
project_data[project_data == "Strongly disagree"] = "Disagree"
sub_project_data = dplyr::select(project_data, time.work, time.no.adult, time.friend, time.school.act, time.reading, time.church, time.excersize, time.HW)
#sub_project_data = na.omit(sub_project_data)
trainIndex = createDataPartition(sub_project_data$time.HW, p = 0.7, list = FALSE, times=1)
projectTrain = sub_project_data[trainIndex,]
projectTest = sub_project_data[-trainIndex,]
project.model = train(time.HW ~., data=projectTrain, ntree=100)
project.pred = predict(project.model, projectTest)
with(projectTest, table(project.pred, time.HW))
```

```{r}
trainIndex = createDataPartition(numeric_data$time.HW, p = 0.7, list = FALSE, times=1)

numericTrain = numeric_data[trainIndex,]
#mtry = 2 with NAs is best
forest2 = randomForest(time.HW ~., data = numericTrain, importance = TRUE, ntree = 1000, mtry = 2, do.trace = TRUE)
forest5 = randomForest(time.HW ~., data = numericTrain, importance = TRUE, ntree = 1000, mtry = 5, do.trace = TRUE)
forest7 = randomForest(time.HW ~., data = numericTrain, importance = TRUE, ntree = 1000, mtry = 7, do.trace = TRUE)
forest10 = randomForest(time.HW ~., data = numericTrain, importance = TRUE, ntree = 1000, mtry = 10, do.trace = TRUE)
varImpPlot(forest2, sort=TRUE)
varImpPlot(forest5, sort=TRUE)
varImpPlot(forest7, sort=TRUE)
varImpPlot(forest10, sort=TRUE)


require(pROC)
rf.roc<-roc(iris$Species,iris.rf$votes[,2])
plot(rf.roc)
auc(rf.roc)
```

